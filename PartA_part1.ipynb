{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9eddd5af-45c7-4652-8a32-a5751ec7bda3",
          "showTitle": false,
          "title": ""
        },
        "id": "XUhp4qo3iqEG"
      },
      "source": [
        "#Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "009a0a55-5d99-4e9d-99aa-b50335342677",
          "showTitle": false,
          "title": ""
        },
        "id": "uAwU5as2iqEQ"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "694e5f54-169f-4245-a63f-170911ee0c81",
          "showTitle": false,
          "title": ""
        },
        "id": "kZJ4CNoHiqEU"
      },
      "source": [
        "###Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3d11ae48-e75b-44d2-91cd-a40c84003e90",
          "showTitle": false,
          "title": ""
        },
        "id": "3pjy1IzAiqEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def init_spark(app_name: str):\n",
        " spark = SparkSession.builder.appName(app_name).getOrCreate()\n",
        " sc = spark.sparkContext\n",
        " return spark, sc\n",
        "\n",
        "spark = SparkSession.builder.appName(\"my project 1\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc\n",
        "\n",
        "# Read a CSV into a dataframe\n",
        "def load_PD_file(filename_or_dir, schema) :\n",
        "    dataPath = \"/mnt/ddscoursedatastorage/fwm-stb-data/\" + filename_or_dir\n",
        "    df = spark.read.format(\"csv\")\\\n",
        "      .option(\"header\",\"false\")\\\n",
        "      .option(\"delimiter\", \"|\")\\\n",
        "      .schema(schema)\\\n",
        "      .load(dataPath)\n",
        "    return df\n",
        "\n",
        "# Reading the Reference Parquet files\n",
        "\n",
        "ref_data_df = spark.read.parquet('/ref_data_raw').withColumnRenamed(\"_device-id\",\"device_id\")\\\n",
        "                                                .withColumnRenamed(\"_dma\",\"dma\")\\\n",
        "                                                .withColumnRenamed(\"_dma-code\",\"dma_code\")\\\n",
        "                                                .withColumnRenamed(\"_household-id\",\"household_id\")\\\n",
        "                                                .withColumnRenamed(\"_household-type\",\"household_type\")\\\n",
        "                                                .withColumnRenamed(\"_system-type\",\"system_type\")\\\n",
        "                                                .withColumnRenamed(\"_zipcode\",\"zipcode\")\n",
        "\n",
        "# Reading the Daily Programs CSV file\n",
        "\n",
        "daily_prog_schema =  StructType([StructField('prog_code',StringType()),\n",
        "                     StructField('title',StringType()),\n",
        "                     StructField('genre',StringType()),\n",
        "                     StructField('air_date',StringType()),\n",
        "                     StructField('air_time',StringType()),\n",
        "                     StructField('Duration',FloatType())\n",
        "                                       ])\n",
        "program_data_df = load_PD_file(\"Daily program data/\" , daily_prog_schema  )\n",
        "\n",
        "\n",
        "# Reading the 2.5% sample of the viewing data from a Parquet file\n",
        "\n",
        "viewing_data_df = spark.read.parquet('/sample_viewing_2_5percent')\n",
        "\n",
        "\n",
        "# Reading the Demographic CSV file\n",
        "\n",
        "demographic_schema =  StructType([StructField('household_id',StringType()),\n",
        "                      StructField('household_size',IntegerType()),\n",
        "                      StructField('num_adults',IntegerType()),\n",
        "                      StructField('num_generations',IntegerType()),\n",
        "                      StructField('adult_range',StringType()),\n",
        "                      StructField('marital_status',StringType()),\n",
        "                      StructField('race_code',StringType()),\n",
        "                      StructField('presence_children',StringType()),\n",
        "                      StructField('num_children',IntegerType()),\n",
        "                      StructField('age_children',StringType()), #format like range - 'bitwise'\n",
        "                      StructField('age_range_children',StringType()),\n",
        "                      StructField('dwelling_type',StringType()),\n",
        "                      StructField('home_owner_status',StringType()),\n",
        "                      StructField('length_residence',IntegerType()),\n",
        "                      StructField('home_market_value',StringType()),\n",
        "                      StructField('num_vehicles',IntegerType()),\n",
        "                      StructField('vehicle_make',StringType()),\n",
        "                      StructField('vehicle_model',StringType()),\n",
        "                      StructField('vehicle_year',IntegerType()),\n",
        "                      StructField('net_worth',IntegerType()),\n",
        "                      StructField('income',StringType()),\n",
        "                      StructField('gender_individual',StringType()),\n",
        "                      StructField('age_individual',IntegerType()),\n",
        "                      StructField('education_highest',StringType()),\n",
        "                      StructField('occupation_highest',StringType()),\n",
        "                      StructField('education_1',StringType()),\n",
        "                      StructField('occupation_1',StringType()),\n",
        "                      StructField('age_2',IntegerType()),\n",
        "                      StructField('education_2',StringType()),\n",
        "                      StructField('occupation_2',StringType()),\n",
        "                      StructField('age_3',IntegerType()),\n",
        "                      StructField('education_3',StringType()),\n",
        "                      StructField('occupation_3',StringType()),\n",
        "                      StructField('age_4',IntegerType()),\n",
        "                      StructField('education_4',StringType()),\n",
        "                      StructField('occupation_4',StringType()),\n",
        "                      StructField('age_5',IntegerType()),\n",
        "                      StructField('education_5',StringType()),\n",
        "                      StructField('occupation_5',StringType()),\n",
        "                      StructField('polit_party_regist',StringType()),\n",
        "                      StructField('polit_party_input',StringType()),\n",
        "                      StructField('household_clusters',StringType()),\n",
        "                      StructField('insurance_groups',StringType()),\n",
        "                      StructField('financial_groups',StringType()),\n",
        "                      StructField('green_living',StringType())\n",
        "                                       ])\n",
        "\n",
        "demographic_data_df = load_PD_file(\"demographic/\" , demographic_schema  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1cdd68d8-2e2d-48ee-a713-4d5243898da1",
          "showTitle": false,
          "title": ""
        },
        "id": "yunPNqQWiqEW"
      },
      "source": [
        "#Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0c7bb9fb-5020-4f7d-be5e-6217a3904dd8",
          "showTitle": false,
          "title": ""
        },
        "id": "_F1kbNohiqEX"
      },
      "source": [
        "##1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "9754df9d-78a9-4532-857e-5ed782664731",
          "showTitle": false,
          "title": ""
        },
        "id": "d07kVnG9iqEY"
      },
      "source": [
        "####preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "769aaa01-30cf-4f81-9c8a-fb7e69ad968f",
          "showTitle": false,
          "title": ""
        },
        "id": "HvGC7XbJiqEY"
      },
      "outputs": [],
      "source": [
        "# Preprocess and transform the Reference Data\n",
        "program_data_df_2 = program_data_df.drop('title')\n",
        "ref_data_df_2 = ref_data_df.select(\"household_id\", \"device_id\", \"dma\").na.drop().dropDuplicates()\n",
        "viewing_data_df_2 = viewing_data_df.select(\"device_id\", \"event_date\", \"prog_code\")\n",
        "demographic_data_df_2 = demographic_data_df.select(\"household_id\", \"household_size\", \"num_adults\", \"net_worth\", \"income\").distinct()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c86008cb-4d3b-4936-b684-992229f64932",
          "showTitle": false,
          "title": ""
        },
        "id": "0zZ3AEadiqEZ"
      },
      "source": [
        "####demographic-Data dataframe Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1f1026f8-8641-4d8e-afd0-e4a700a2e54c",
          "showTitle": false,
          "title": ""
        },
        "id": "Ik6Jh2sIiqEZ",
        "outputId": "45ca9764-2a5f-4b3b-bca1-f5d61df18442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out[16]: DataFrame[household_id: string, cond_3: int, lower_than_avg: int, large_family: int]"
          ]
        }
      ],
      "source": [
        "demographic_data_df_2.cache() #caching demographic\n",
        "\n",
        "#fixing values\n",
        "mapping = {'A': 10, 'B': 11, 'C': 12, 'D': 13}\n",
        "\n",
        "demographic_data_df_2 = demographic_data_df_2.withColumn('income',\n",
        "                                when(col('income') == 'A', mapping['A'])\n",
        "                               .when(col('income') == 'B', mapping['B'])\n",
        "                               .when(col('income') == 'C', mapping['C'])\n",
        "                               .when(col('income') == 'D', mapping['D'])\n",
        "                               .otherwise(col('income')))\n",
        "\n",
        "#getting rid of unnecessary records\n",
        "demographic_data_df_2 = demographic_data_df_2.filter((col('num_adults').isNotNull()) |\n",
        "                                                (col('income').isNotNull()) |\n",
        "                                                (col('net_worth').isNotNull()))\n",
        "\n",
        "#flagging families with less than 3 adults and networth higher than 8\n",
        "demographic_data_df_2 = demographic_data_df_2.withColumn('cond_3', \\\n",
        "                                                     when(((col('num_adults') < 3) & (col('num_adults').isNotNull())) & (col('net_worth') > 8) & (col('net_worth').isNotNull()), 1).otherwise(0)).drop('num_adults', 'net_worth')\n",
        "\n",
        "#finding average income\n",
        "avg_income = demographic_data_df_2.filter((col('income') != 'null') & (col('income').isNotNull())).agg(avg('income').alias('avg_income')).first()['avg_income']\n",
        "demographic_data_df_2 = demographic_data_df_2.withColumn('lower_than_avg',\n",
        "                                                     when((col('income') < avg_income) & (col('income').isNotNull()), 1)\n",
        "                                                     .otherwise(0)).drop('income')\n",
        "\n",
        "# Flagging large families\n",
        "demographic_data_df_2 = demographic_data_df_2.withColumn('large_family', when((col('household_size') >= 8) & (col('household_size').isNotNull()), 1).otherwise(0)).drop('household_size').distinct()\n",
        "\n",
        "demographic_data_df_2.unpersist() #unpersisting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "192ff9aa-2ddb-4e41-823f-6105e1edac49",
          "showTitle": false,
          "title": ""
        },
        "id": "zm_WOB-iiqEa"
      },
      "source": [
        "####Viewing-Data dataframe transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2e4bd92b-b428-4d72-b881-f1872c3109ee",
          "showTitle": false,
          "title": ""
        },
        "id": "FeNpuHyJiqEa",
        "outputId": "a4b118e2-473d-4bc9-b26f-e0ea1e6dcc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out[17]: DataFrame[device_id: string, prog_code: string, cond_1: int]"
          ]
        }
      ],
      "source": [
        "viewing_data_df_2.cache() #cachine viewing datafrane\n",
        "\n",
        "#counting daily events per device\n",
        "viewing_with_daily_events_df = viewing_data_df_2.groupBy('device_id', 'event_date').agg(count('*').alias('num_daily_events'))\n",
        "viewing_with_daily_events_df = viewing_with_daily_events_df.groupBy('device_id').agg(sum('num_daily_events').alias('total_events'))\n",
        "\n",
        "#counting number of active days per device\n",
        "viewing_data_with_num_dates_df = viewing_data_df_2.select('device_id', 'event_date').distinct().groupBy('device_id').agg(count('event_date').alias('num_days'))\n",
        "\n",
        "#adding data to viewing data frame\n",
        "viewing_data_df_2 = viewing_data_df_2.join(viewing_with_daily_events_df, on='device_id', how='left')\n",
        "viewing_data_df_2 = viewing_data_df_2.join(viewing_data_with_num_dates_df, on='device_id', how='left').drop('event_date').distinct()\n",
        "\n",
        "#finding average daily activity per device\n",
        "viewing_data_df_2 = viewing_data_df_2.withColumn('avg_daily_events', col('total_events')/col('num_days'))\n",
        "\n",
        "#flagging devices that average less than 5 events per day\n",
        "viewing_data_df_2 = viewing_data_df_2.withColumn('cond_1', when(col('avg_daily_events') < 5, 1).otherwise(0)).drop('avg_daily_events', 'total_events', 'num_days')\n",
        "\n",
        "viewing_data_df_2.unpersist()  # Unpersist the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "d1e79e14-bc14-46d1-82a6-50c0df0085f3",
          "showTitle": false,
          "title": ""
        },
        "id": "0EgmCHrwiqEa"
      },
      "source": [
        "####Reference-Data dataframe transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c8630a29-27f1-402c-8de6-c5c9e9cbff1d",
          "showTitle": false,
          "title": ""
        },
        "id": "qhkPpshriqEa",
        "outputId": "6922de86-ec1b-4d95-87b8-d172d3b9e541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out[18]: DataFrame[household_id: bigint, device_id: string, cond_2: int, more_than_3_dev: int]"
          ]
        }
      ],
      "source": [
        "ref_data_df_2.cache()  # Cache the DataFrame\n",
        "\n",
        "#flagging devices who's dma contains 'z'\n",
        "ref_data_df_2 = ref_data_df_2.withColumn('cond_2', when((col('dma').like('%z%')) | (col('dma').like('%Z%')), 1).otherwise(0)).drop('dma')\n",
        "\n",
        "# Counting devices per household\n",
        "household_devices_df = ref_data_df_2.select('household_id', 'device_id').groupBy('household_id').agg(countDistinct('device_id').alias('num_devices'))\n",
        "\n",
        "#adding num_devices to reference data dataframe\n",
        "ref_data_df_2 = ref_data_df_2.join(household_devices_df, on='household_id', how=\"left\")\n",
        "\n",
        "# Flagging houses with more than 3 devices\n",
        "ref_data_df_2 = ref_data_df_2.withColumn('more_than_3_dev', when(col('num_devices') > 3, 1).otherwise(0)).drop('num_devices').distinct()\n",
        "\n",
        "ref_data_df_2.unpersist()  # Unpersist the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "6265aecd-3fce-418a-90e9-73dff7d70ceb",
          "showTitle": false,
          "title": ""
        },
        "id": "PoYhwAq-iqEb"
      },
      "source": [
        "####Program-Data dataframe transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cde869c5-f39a-497a-96ea-a0467ed9bb02",
          "showTitle": false,
          "title": ""
        },
        "id": "I7ZKjVEBiqEb",
        "outputId": "e3c169c7-80f1-42fd-fea1-207c415da0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out[19]: DataFrame[prog_code: string, air_date: string, air_time: string, air_day: int, cond_6: int]"
          ]
        }
      ],
      "source": [
        "program_data_df_2.cache()\n",
        "\n",
        "# Converting date to days of week\n",
        "program_data_df_2 = program_data_df_2.withColumn('air_day', to_date(program_data_df_2[\"air_date\"], 'yyyyMMdd'))\n",
        "program_data_df_2 = program_data_df_2.withColumn('air_day', dayofweek(program_data_df_2[\"air_day\"]))\n",
        "\n",
        "#checking for shows that aired on the weekend\n",
        "weekend_shows = program_data_df_2.select('prog_code', 'air_day', 'air_time').filter((((col('air_day') == 6) & (hour(col('air_time')) >= 18)) | (col('air_day') == 7) & (hour(col('air_time')) <= 19))).select('prog_code').distinct().collect()\n",
        "weekend_shows = [row.prog_code for row in weekend_shows]\n",
        "\n",
        "#splitting genres for convenience\n",
        "program_data_df_2 = program_data_df_2.withColumn('genre', split(col('genre'), ','))\n",
        "\n",
        "# flagging programs that answer condition 6\n",
        "program_data_df_2 = program_data_df_2.withColumn('cond_6', when(((array_contains(col('genre'), 'Talk')) |\n",
        "                                                            (array_contains(col('genre'), 'Politics')) |\n",
        "                                                            (array_contains(col('genre'), 'News')) |\n",
        "                                                            (array_contains(col('genre'), 'Community')) |\n",
        "                                                            (array_contains(col('genre'), 'Crime'))) &\n",
        "                                                           (col('duration') > 35), 1).otherwise(0)).drop('genre', 'duration').distinct()\n",
        "\n",
        "\n",
        "program_data_df_2.unpersist()  # Unpersist the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "766df700-d535-4076-937c-4836690afa0a",
          "showTitle": false,
          "title": ""
        },
        "id": "q-DN5oU9iqEb"
      },
      "source": [
        "####Combining dataframes and completing the conditions that require data from seperate dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d657a034-9dda-47ed-bd77-b5a7342b2faa",
          "showTitle": false,
          "title": ""
        },
        "id": "bgyC4opbiqEb"
      },
      "outputs": [],
      "source": [
        "#combining demographic data with reference data\n",
        "joined_demo_ref_df = ref_data_df_2.join(demographic_data_df_2, on='household_id', how='left')\n",
        "\n",
        "demographic_data_df_2.unpersist() #unpersist demographic dataframe\n",
        "joined_demo_ref_df.cache() #cache joined dataframe\n",
        "\n",
        "#flagging shows that answer condition 5\n",
        "joined_demo_ref_df = joined_demo_ref_df.withColumn('cond_5', when((col('lower_than_avg') == 1) &\n",
        "                                                                 (col('more_than_3_dev') == 1), 1).otherwise(0)) \\\n",
        "                                      .select('device_id', 'cond_2', 'cond_3', 'cond_5', 'large_family')\n",
        "\n",
        "#replacing null values with 0s\n",
        "joined_demo_ref_df = joined_demo_ref_df.na.fill(0)\n",
        "\n",
        "#combining ref_demo with viewing by device\n",
        "joined_demo_ref_viewing_df = viewing_data_df_2.join(joined_demo_ref_df, on='device_id', how='left').drop('device_id').na.fill(0).distinct()\n",
        "\n",
        "joined_demo_ref_df.unpersist() #unpersist joined\n",
        "joined_demo_ref_viewing_df.cache()\n",
        "\n",
        "#combining program data with the rest\n",
        "combined_df = program_data_df_2.join(joined_demo_ref_viewing_df, on='prog_code', how='left').distinct()\n",
        "\n",
        "joined_demo_ref_viewing_df.unpersist()\n",
        "combined_df.cache()\n",
        "\n",
        "#flagging program code that were watched at least once by a large family\n",
        "large_family_shows = combined_df.select('prog_code', 'large_family').filter(col('large_family') == 1).select('prog_code').distinct().collect()\n",
        "large_family_shows = [row.prog_code for row in large_family_shows]\n",
        "\n",
        "#adding datato the main dataframe\n",
        "#combined_df = combined_df.withColumn('large_family_show', when(col('prog_code').isin(large_family_shows), 1).otherwise(0)).drop('large_family')\n",
        "\n",
        "#flagging shows that aired on weekend and were watched by a large family\n",
        "combined_df = combined_df.withColumn('cond_4', when((col('prog_code').isin(weekend_shows)) & (col('prog_code').isin(large_family_shows)), 1). \\\n",
        "                                     otherwise(0)).drop('air_date', 'air_time', 'air_day', 'large_family').fillna(0).distinct()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c9db966d-e620-432c-9939-a0d55a94c21f",
          "showTitle": false,
          "title": ""
        },
        "id": "fMy-yuiuiqEc"
      },
      "source": [
        "####Counting conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f95ec110-8fd7-4fdc-8cd0-71f0252b1647",
          "showTitle": false,
          "title": ""
        },
        "id": "7Gt8oNhNiqEc",
        "outputId": "42ace714-b796-4d76-b827-8e928b3f4128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of programs that answer condition 1:  9135\nnumber of programs that answer condition 2:  235426\nnumber of programs that answer condition 3:  180058\nnumber of programs that answer condition 4:  66047\nnumber of programs that answer condition 5:  255486\nnumber of programs that answer condition 6:  33648\n"
          ]
        }
      ],
      "source": [
        "#counting programs that answer conditions\n",
        "num_cond_1 = combined_df.filter(col('cond_1') == 1).select('prog_code').distinct().count()\n",
        "num_cond_2 = combined_df.filter(col('cond_2') == 1).select('prog_code').distinct().count()\n",
        "num_cond_3 = combined_df.filter(col('cond_3') == 1).select('prog_code').distinct().count()\n",
        "num_cond_4 = combined_df.filter(col('cond_4') == 1).select('prog_code').distinct().count()\n",
        "num_cond_5 = combined_df.filter(col('cond_5') == 1).select('prog_code').distinct().count()\n",
        "num_cond_6 = combined_df.filter(col('cond_6') == 1).select('prog_code').distinct().count()\n",
        "\n",
        "print(\"number of programs that answer condition 1: \", num_cond_1)\n",
        "print(\"number of programs that answer condition 2: \", num_cond_2)\n",
        "print(\"number of programs that answer condition 3: \", num_cond_3)\n",
        "print(\"number of programs that answer condition 4: \", num_cond_4)\n",
        "print(\"number of programs that answer condition 5: \", num_cond_5)\n",
        "print(\"number of programs that answer condition 6: \", num_cond_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "29001ec8-baa8-414b-8102-a72ffc0eb87c",
          "showTitle": false,
          "title": ""
        },
        "id": "8kwtrt1MiqEc"
      },
      "source": [
        "##1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8d968f55-a0ca-4bdb-9345-b1e3836697d0",
          "showTitle": false,
          "title": ""
        },
        "id": "uuv6KFXPiqEc"
      },
      "source": [
        "##Question 1.2_1 <br>\n",
        "<br>\n",
        "\n",
        "###Another solutino to the problem:##\n",
        "\n",
        "- start of by working with each scheme individually, performing as much of the necessary operations on the seperate tables.\n",
        "- establishing clear logical connections between the different datasets and join them when necessary. <br>\n",
        "<br>\n",
        "\n",
        "###Pros & Cons##\n",
        "\n",
        "**Pro 1:** if we combine all the data into one table early on, It will be very easy to work with because all the qualities are in one table, so you can access all the necessary properties of each record without alternating between different tables and joining. <br>\n",
        "**Pro 2:** combining all the data into one big table means we will only use that table throughout the entire process, which means we can cache/persist it early on, and we won't have to worry about memory management.\n",
        "\n",
        "**Con 1:** Joining all the tables when they still contain all the records (before filtering anything out) can be very heavy computationally. Addtionally, naturally this table will have alot more records, meaning with each operation such as filtering, we will need to go through all the records in the big table, even if using one of the sub-tables would have been sufficient. <br>\n",
        "**Con 2:** Increased complexity: Joining all the data into one table requires mapping and integrating different data structures, formats, aliases and naming conventions. Needless to say this can be very complex when dealing with datasets that encompass a vast array of diverse properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5f5db362-df00-4da8-b4ec-ee62e324bfd3",
          "showTitle": false,
          "title": ""
        },
        "id": "Qzud28NFiqEd"
      },
      "source": [
        "##1.2_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "b0c8dcda-8c71-4617-a8e6-69e1ecbdbd17",
          "showTitle": false,
          "title": ""
        },
        "id": "pHLH6KFWiqEe"
      },
      "source": [
        "####finding all program codes of malicious programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d232e8f9-6677-4000-b79a-b1ccbd9f9519",
          "showTitle": false,
          "title": ""
        },
        "id": "Ofm41AyBiqEe"
      },
      "outputs": [],
      "source": [
        "malicious_progs_df = combined_df.filter( \\\n",
        "    col('cond_1') + col('cond_2') + col('cond_3') \\\n",
        "    + col('cond_4') + col('cond_5') + col('cond_6') >= 4 \\\n",
        "    ).select('prog_code').distinct().orderBy('prog_code', ascending=True)\n",
        "\n",
        "malicious_progs_df.cache() #caching malicious_progs dataframe\n",
        "\n",
        "#saving a pandas dataframe for the csv\n",
        "malicious_progs_pandas = malicious_progs_df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3a16f441-7fbe-4825-8a23-e2a0e57a3a82",
          "showTitle": false,
          "title": ""
        },
        "id": "0Gve5rj6iqEf"
      },
      "source": [
        "####Displaying all malicious programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c1960f76-06fa-435c-bc61-3eda97291aa8",
          "showTitle": false,
          "title": ""
        },
        "id": "GunWLbWiiqEf"
      },
      "outputs": [],
      "source": [
        "#displaying to save manually\n",
        "display(malicious_progs_pandas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f2939ea9-cb73-44b4-a7cb-310de4d67dc3",
          "showTitle": false,
          "title": ""
        },
        "id": "jCJfzOhsiqEg"
      },
      "source": [
        "####Showing top 150 malicious programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f788526b-e7a0-4d8a-a53a-cd3039a791ab",
          "showTitle": false,
          "title": ""
        },
        "id": "XZU2V3HtiqEg",
        "outputId": "d678d08f-53f4-4ae0-cb48-9f7d56e5c975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n|prog_code     |\n+--------------+\n|EP000009540005|\n|EP000018936972|\n|EP000018936974|\n|EP000018936997|\n|EP000018936999|\n|EP000018937001|\n|EP000018937003|\n|EP000018937005|\n|EP000018937032|\n|EP000018937034|\n|EP000018937036|\n|EP000018937038|\n|EP000018937060|\n|EP000018937062|\n|EP000018937064|\n|EP000018937088|\n|EP000018937090|\n|EP000018937092|\n|EP000018937094|\n|EP000018937116|\n|EP000018937118|\n|EP000018937120|\n|EP000018937122|\n|EP000018937124|\n|EP000018937152|\n|EP000018937154|\n|EP000018937156|\n|EP000018937158|\n|EP000018937180|\n|EP000018937182|\n|EP000018937184|\n|EP000018937186|\n|EP000018937188|\n|EP000018937215|\n|EP000018937217|\n|EP000018937219|\n|EP000018937221|\n|EP000018937243|\n|EP000018937245|\n|EP000018937247|\n|EP000018937249|\n|EP000018937271|\n|EP000018937273|\n|EP000018937275|\n|EP000018937277|\n|EP000018937279|\n|EP000018937306|\n|EP000018937308|\n|EP000018937310|\n|EP000018937312|\n|EP000018937336|\n|EP000037100945|\n|EP000041755641|\n|EP000041755644|\n|EP000041755654|\n|EP000041755655|\n|EP000041755663|\n|EP000041755673|\n|EP000041755678|\n|EP000041755683|\n|EP000041755694|\n|EP000041755698|\n|EP000041755703|\n|EP000041755708|\n|EP000041755720|\n|EP000041755724|\n|EP000041755733|\n|EP000041755739|\n|EP000041755744|\n|EP000041755754|\n|EP000041755759|\n|EP000041755764|\n|EP000041755772|\n|EP000041755777|\n|EP000041755782|\n|EP000041755789|\n|EP000041755792|\n|EP000041755796|\n|EP000041755803|\n|EP000041755815|\n|EP000041755818|\n|EP000041755823|\n|EP000170700528|\n|EP000170700541|\n|EP000170700569|\n|EP000170700595|\n|EP000170700629|\n|EP000170700634|\n|EP000170700635|\n|EP000170700636|\n|EP000170700637|\n|EP000170700640|\n|EP000170700647|\n|EP000170700651|\n|EP000170700652|\n|EP000170700675|\n|EP000170700680|\n|EP000170700687|\n|EP000170700688|\n|EP000170700691|\n|EP000170700707|\n|EP000170700713|\n|EP000170700716|\n|EP000170700719|\n|EP000170700725|\n|EP000170700744|\n|EP000170700747|\n|EP000170700754|\n|EP000170700759|\n|EP000170700767|\n|EP000170700769|\n|EP000170700781|\n|EP000170700785|\n|EP000170700787|\n|EP000170700793|\n|EP000170700801|\n|EP000170700814|\n|EP000170700833|\n|EP000170700863|\n|EP000170700874|\n|EP000170700919|\n|EP000170700925|\n|EP000170700953|\n|EP000170701022|\n|EP000170740013|\n|EP000170740017|\n|EP000170740019|\n|EP000170740020|\n|EP000173500060|\n|EP000173500061|\n|EP000173500074|\n|EP000173500075|\n|EP000173500076|\n|EP000173500081|\n|EP000173500082|\n|EP000173500088|\n|EP000173500096|\n|EP000188800096|\n|EP000188800100|\n|EP000188800103|\n|EP000188800112|\n|EP000188800113|\n|EP000188800114|\n|EP000188800124|\n|EP000191775944|\n|EP000191775959|\n|EP000191775963|\n|EP000191775969|\n|EP000191775993|\n|EP000191775999|\n+--------------+\nonly showing top 150 rows\n\n"
          ]
        }
      ],
      "source": [
        "#printing the malicious programs\n",
        "malicious_progs_df.show(150, truncate=False)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "Untitled Notebook 2023-06-04 16:08:24",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}